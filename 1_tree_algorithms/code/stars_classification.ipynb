{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHBBLLnGNMcL"
      },
      "source": [
        "# Implementation of all decision tree models and optimizations (using the already split datasets)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Library requirements"
      ],
      "metadata": {
        "id": "BUv6VtlGE3IF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install disarray"
      ],
      "metadata": {
        "id": "2qAJrqNq1UgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OY__khm9NavE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import tree\n",
        "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
        "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculationort pandas as pd\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.projections.polar import np\n",
        "import disarray\n",
        "import json\n",
        "import csv"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reading train and test data"
      ],
      "metadata": {
        "id": "Hz0GOb75Er6g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RAvAgJ5LQUOa"
      },
      "outputs": [],
      "source": [
        "X_train = pd.read_csv(\"./Data/X_train.csv\")\n",
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6KePr6WS7fn"
      },
      "outputs": [],
      "source": [
        "y_train = pd.read_csv(\"./Data/y_train.csv\")\n",
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QzplHNmtSzON"
      },
      "outputs": [],
      "source": [
        "X_test = pd.read_csv(\"./Data/X_test.csv\")\n",
        "X_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xa3sejaFTGNB"
      },
      "outputs": [],
      "source": [
        "y_test = pd.read_csv(\"./Data/y_test.csv\")\n",
        "y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3q4yi2iYevzM"
      },
      "outputs": [],
      "source": [
        "# getting the labels and all the features\n",
        "label_names = np.sort(y_train['class'].unique())\n",
        "feature_names = X_train.columns\n",
        "print(\"label_names: \", label_names)\n",
        "print(\"feature_names: \", feature_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and testing non-optimized decision tree"
      ],
      "metadata": {
        "id": "Ty0kCbaSFT1z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhuJgs91TQZo"
      },
      "outputs": [],
      "source": [
        "# create decision tree classifer object\n",
        "clf_non_optimized = DecisionTreeClassifier()\n",
        "\n",
        "# train the decision tree classifer\n",
        "clf_non_optimized = clf_non_optimized.fit(X_train, y_train)\n",
        "\n",
        "# predict the response for test dataset\n",
        "y_pred_non_optimized = clf_non_optimized.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2cY2RZcjTcjt"
      },
      "outputs": [],
      "source": [
        "# calculating accuracy\n",
        "accuracy = metrics.accuracy_score(y_test, y_pred_non_optimized)\n",
        "print(\"Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'This is the accuracy for the non optimized decision tree'\n",
        "\n",
        "with open('non_optimized_results.csv','w') as f:\n",
        "    f.write(text)\n",
        "    f.write(\"\\n\"+str(accuracy)+\"\\n\")\n"
      ],
      "metadata": {
        "id": "ZbN29OPYDqXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQCeoAUBTgSm"
      },
      "outputs": [],
      "source": [
        "# making the confusion matrix for the results for non-optimized decision tree\n",
        "c_matrix = confusion_matrix(y_test, y_pred_non_optimized)\n",
        "c_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_c_matrix = pd.DataFrame(c_matrix)\n",
        "df_c_matrix"
      ],
      "metadata": {
        "id": "-jR_H5sX0-45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'These are the confusion matrix values. True labels along y-axis and predicted labels along x-axis'\n",
        "\n",
        "with open('non_optimized_results.csv','a') as f:\n",
        "    f.write(\"\\n\" + text + \"\\n\")\n",
        "\n",
        "df_c_matrix.to_csv(\"non_optimized_results.csv\", mode='a')"
      ],
      "metadata": {
        "id": "dOHGIhmb2-kR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculating precision, recall, and f1\n",
        "df = pd.DataFrame(c_matrix, index= ['0', '1','2'],columns=['0', '1','2'])\n",
        "imp_metrics = df.da.export_metrics(metrics_to_include=['precision', 'recall', 'f1'])\n",
        "imp_metrics"
      ],
      "metadata": {
        "id": "QJVecIcbh9KH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'These are the 1. precision 2. recall and 3. f1 scores'\n",
        "\n",
        "with open('non_optimized_results.csv','a') as f:\n",
        "    f.write(\"\\n\" + text +\"\\n\")\n",
        "\n",
        "imp_metrics.to_csv('non_optimized_results.csv', mode='a')"
      ],
      "metadata": {
        "id": "gYQc2WgV8H7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7kjp-6kKTjGy"
      },
      "outputs": [],
      "source": [
        "confusion_matrix_display = ConfusionMatrixDisplay.from_predictions(y_test, y_pred_non_optimized)\n",
        "confusion_matrix_display.figure_.savefig('confusion_matrix_non_optimized.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tree visualization and feature analysis for non-optimized decision tree"
      ],
      "metadata": {
        "id": "956MjFRRFiK9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BCNQTCxFTk-f"
      },
      "outputs": [],
      "source": [
        "# textual representation of the decision tree\n",
        "text_representation = tree.export_text(clf_non_optimized)\n",
        "print(text_representation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sm98JOE0Tnh3"
      },
      "outputs": [],
      "source": [
        "# visual representation of the decision tree\n",
        "\n",
        "label_names_str = [item for item in label_names.astype(str)]\n",
        "figure_tree = plt.figure(figsize=(100,100))\n",
        "_ = tree.plot_tree(clf_non_optimized,\n",
        "                   feature_names=feature_names,\n",
        "                   class_names=label_names_str,\n",
        "                   filled=True)\n",
        "figure_tree.savefig(\"decision_tree_non_optimized.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jLHKPEuQTxxV"
      },
      "outputs": [],
      "source": [
        "# calculating feature importance scores\n",
        "feat_importance = clf_non_optimized.feature_importances_\n",
        "print(\"Feature Importance = \" + str(feat_importance))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ops6ukYfU7W6"
      },
      "outputs": [],
      "source": [
        "# getting the top features\n",
        "top_feature_names = []\n",
        "for i in range(len(feature_names)):\n",
        "  if feat_importance[i] > 0.006:\n",
        "    top_feature_names.append(feature_names[i])\n",
        "\n",
        "top_feature_names = np.array(top_feature_names)\n",
        "\n",
        "print(top_feature_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2l1gJS7rU_Vv"
      },
      "outputs": [],
      "source": [
        "# visual representation of the feature importance scores\n",
        "feat_importances = pd.DataFrame(clf_non_optimized.feature_importances_, index=feature_names)\n",
        "plot = feat_importances.plot(kind='bar', figsize=(6,4))\n",
        "fig = plot.get_figure()\n",
        "fig.savefig(\"feature_importances_non_optimized.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and testing optimized decision tree (after hyperparameter tuning)"
      ],
      "metadata": {
        "id": "mPkkTamiJxgi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_j-TpF_VmLR"
      },
      "outputs": [],
      "source": [
        "# all the hyperparameters to be tuned and a range of value for them\n",
        "tree_para = {'criterion':['gini','entropy','log_loss'],'splitter':['best', 'random'], 'max_depth':np.arange(1,10), 'max_leaf_nodes':np.arange(2,10)}\n",
        "\n",
        "# create decision tree classifer object\n",
        "clf_optimized = GridSearchCV(DecisionTreeClassifier(), tree_para, cv=5)\n",
        "\n",
        "# train the decision tree classifer\n",
        "clf_optimized = clf_optimized.fit(X_train,y_train)\n",
        "\n",
        "# the most optimal values found for the hyperparameters\n",
        "print(clf_optimized.best_params_)\n",
        "\n",
        "# predict the response for test dataset\n",
        "y_pred_optimized = clf_optimized.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculating accuracy\n",
        "accuracy = metrics.accuracy_score(y_test, y_pred_optimized)\n",
        "print(\"Accuracy:\",accuracy)"
      ],
      "metadata": {
        "id": "6fDp9TajL9i8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'This is the accuracy for the optimized decision tree'\n",
        "\n",
        "with open('optimized_results.csv','w') as f:\n",
        "    f.write(text)\n",
        "    f.write(\"\\n\"+str(accuracy)+\"\\n\")\n"
      ],
      "metadata": {
        "id": "9Rguml-AMESb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7XCydlqIYyn8"
      },
      "outputs": [],
      "source": [
        "# making the confusion matrix for the results for non-optimized decision tree\n",
        "\n",
        "c_matrix = confusion_matrix(y_test, y_pred_optimized)\n",
        "c_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_c_matrix = pd.DataFrame(c_matrix)\n",
        "df_c_matrix"
      ],
      "metadata": {
        "id": "_60ncPfcMJcd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'These are the confusion matrix values. True labels along y-axis and predicted labels along x-axis'\n",
        "\n",
        "with open('optimized_results.csv','a') as f:\n",
        "    f.write(\"\\n\" + text + \"\\n\")\n",
        "\n",
        "df_c_matrix.to_csv('optimized_results.csv', mode='a')"
      ],
      "metadata": {
        "id": "qahDvul4MMVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculating precision, recall, and f1\n",
        "\n",
        "df = pd.DataFrame(c_matrix, index= ['0', '1','2'],columns=['0', '1','2'])\n",
        "imp_metrics = df.da.export_metrics(metrics_to_include=['precision', 'recall', 'f1'])\n",
        "imp_metrics"
      ],
      "metadata": {
        "id": "q0Do-stXgqq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'These are the 1. precision 2. recall and 3. f1 scores'\n",
        "\n",
        "with open('optimized_results.csv','a') as f:\n",
        "    f.write(\"\\n\" + text +\"\\n\")\n",
        "\n",
        "imp_metrics.to_csv('optimized_results.csv', mode='a')"
      ],
      "metadata": {
        "id": "Aer3Ozp1mwrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zvq7bzuZqHo"
      },
      "outputs": [],
      "source": [
        "confusion_matrix_display = ConfusionMatrixDisplay.from_predictions(y_test, y_pred_optimized)\n",
        "confusion_matrix_display.figure_.savefig('confusion_matrix_optimized.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tree visualization and feature analysis for optimized decision tree"
      ],
      "metadata": {
        "id": "-ZIX-f89KApu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTYuwKaPZ0ma"
      },
      "outputs": [],
      "source": [
        "# textual representation of the optimized decision tree\n",
        "text_representation = tree.export_text(clf_optimized.best_estimator_)\n",
        "print(text_representation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7nUeMoiXZ4kf"
      },
      "outputs": [],
      "source": [
        "# visual representation of the optimized decision tree\n",
        "\n",
        "figure_tree = plt.figure(figsize=(50,50))\n",
        "label_names_str = [item for item in label_names.astype(str)]\n",
        "_ = tree.plot_tree(clf_optimized.best_estimator_,\n",
        "                   feature_names=feature_names,\n",
        "                   class_names=label_names_str,\n",
        "                   filled=True)\n",
        "figure_tree.savefig(\"decision_tree_optimizied.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4BFvCNDwZ-Qq"
      },
      "outputs": [],
      "source": [
        "# calculating feature importance scores\n",
        "feat_importance = clf_optimized.best_estimator_.feature_importances_\n",
        "print(\"Feature Importance = \" + str(feat_importance))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0eHU85lZaLY6"
      },
      "outputs": [],
      "source": [
        "# visual representation of the feature importance scores\n",
        "feat_importances = pd.DataFrame(clf_optimized.best_estimator_.feature_importances_, index=feature_names)\n",
        "plot = feat_importances.plot(kind='bar', figsize=(6,4))\n",
        "fig = plot.get_figure()\n",
        "fig.savefig(\"feature_importances_optimized.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJSyt-eSaPnB"
      },
      "outputs": [],
      "source": [
        "# getting the top features\n",
        "top_feature_names = []\n",
        "for i in range(len(feature_names)):\n",
        "  if feat_importance[i] > 0:\n",
        "    top_feature_names.append(feature_names[i])\n",
        "\n",
        "top_feature_names = np.array(top_feature_names)\n",
        "\n",
        "print(top_feature_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbJZLkZxdpRM"
      },
      "source": [
        "# Training and testing optimized and non-optimized models after removing top three features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SukWuU_CbHgb"
      },
      "outputs": [],
      "source": [
        "# deleting the top features of the optimized decision tree from the training data\n",
        "X_train_delete_features = X_train.drop(top_feature_names, axis=1)\n",
        "X_train_delete_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8abjw9ZsbrhG"
      },
      "outputs": [],
      "source": [
        "# deleting the top features of the optimized decision tree from the test data\n",
        "X_test_delete_features = X_test.drop(top_feature_names, axis=1)\n",
        "X_test_delete_features"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# getting the remaining features\n",
        "delete_feature_names = X_test_delete_features.columns"
      ],
      "metadata": {
        "id": "og87de4jD-3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "delete_feature_names"
      ],
      "metadata": {
        "id": "wNbHuc9CXSHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3UqNMOtcvrt"
      },
      "outputs": [],
      "source": [
        "# create decision tree classifer object\n",
        "clf_non_optimized_delete_features = DecisionTreeClassifier()\n",
        "\n",
        "# train decision tree classifer\n",
        "clf_non_optimized_delete_features = clf_non_optimized_delete_features.fit(X_train_delete_features, y_train)\n",
        "\n",
        "# predict the response for test dataset\n",
        "y_pred_non_optimized_delete_features = clf_non_optimized_delete_features.predict(X_test_delete_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gzBc3TJWddCv"
      },
      "outputs": [],
      "source": [
        "# calculating accuracy\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred_non_optimized_delete_features))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xgbe9hRvljkV"
      },
      "outputs": [],
      "source": [
        "# textual represntation of the decision tree for the model trained after deleting top features\n",
        "text_representation = tree.export_text(clf_non_optimized_delete_features)\n",
        "print(text_representation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLkcspErapKd"
      },
      "outputs": [],
      "source": [
        "# visual represntation of the decision tree for the model trained after deleting top features\n",
        "\n",
        "figure_tree = plt.figure(figsize=(100,100))\n",
        "label_names_str = [item for item in label_names.astype(str)]\n",
        "_ = tree.plot_tree(clf_non_optimized_delete_features,\n",
        "                   feature_names=delete_feature_names,\n",
        "                   class_names=label_names_str,\n",
        "                   filled=True)\n",
        "figure_tree.savefig(\"decision_tree_non_optimizied_without3bestfeat.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_lMF9_ClnoQ"
      },
      "outputs": [],
      "source": [
        "# hyperparameter tuning for the model trained after deleting top features\n",
        "\n",
        "tree_para = {'criterion':['gini','entropy','log_loss'],'splitter':['best', 'random'], 'max_depth':np.arange(1,10), 'max_leaf_nodes':np.arange(2,10)}\n",
        "\n",
        "# create decision tree classifer object\n",
        "clf_optimized_delete_features = GridSearchCV(DecisionTreeClassifier(), tree_para, cv=5)\n",
        "\n",
        "# train decision tree classifer\n",
        "clf_optimized_delete_features = clf_optimized_delete_features.fit(X_train_delete_features,y_train)\n",
        "print(clf_optimized_delete_features.best_params_)\n",
        "\n",
        "# predict the response for test dataset\n",
        "y_pred_optimized_delete_features = clf_optimized_delete_features.predict(X_test_delete_features)\n",
        "\n",
        "# calculating accuracy\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred_optimized_delete_features))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTznh4NVl6CD"
      },
      "outputs": [],
      "source": [
        "# textual represntation of the decision tree for the model trained after deleting top features\n",
        "\n",
        "text_representation = tree.export_text(clf_optimized_delete_features.best_estimator_)\n",
        "print(text_representation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_20UwII7a-Z6"
      },
      "outputs": [],
      "source": [
        "# visual represntation of the decision tree for the model trained after deleting top features\n",
        "\n",
        "figure_tree = plt.figure(figsize=(50,50))\n",
        "label_names_str = [item for item in label_names.astype(str)]\n",
        "_ = tree.plot_tree(clf_optimized_delete_features.best_estimator_,\n",
        "                   feature_names=delete_feature_names,\n",
        "                   class_names=label_names_str,\n",
        "                   filled=True)\n",
        "figure_tree.savefig(\"decision_tree_optimizied_without3bestfeat.png\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "BUv6VtlGE3IF",
        "Hz0GOb75Er6g",
        "Ty0kCbaSFT1z",
        "956MjFRRFiK9",
        "mPkkTamiJxgi",
        "-ZIX-f89KApu",
        "sbJZLkZxdpRM"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}