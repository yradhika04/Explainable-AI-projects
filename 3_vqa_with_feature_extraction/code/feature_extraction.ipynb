{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "gDV9aHyh8R9_",
        "i1qP_YXW4Y7l",
        "MF72KS5WjjrB",
        "-XxdUPi_-Ng8",
        "J-Yn1pnEHkmw"
      ],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Library requirements"
      ],
      "metadata": {
        "id": "gDV9aHyh8R9_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hB1O7wNP75RX"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "5cFCYHL34x1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text data preprocessing"
      ],
      "metadata": {
        "id": "i1qP_YXW4Y7l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# getting the dataset from huggingface\n",
        "dataset = load_dataset(\"ashraq/fashion-product-images-small\")\n",
        "dataset"
      ],
      "metadata": {
        "id": "zsnjl4PW5bxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# putting only the required columns of the dataset (from the train split) into a dataframe\n",
        "data_for_df = { 'id': dataset['train']['id'],\n",
        "                'gender' : dataset['train']['gender'],\n",
        "                'category': dataset['train']['masterCategory'],\n",
        "                'text': dataset['train']['productDisplayName'],\n",
        "                # 'addition1': dataset['train']['subCategory'],\n",
        "                'addition2': dataset['train']['season'],\n",
        "                'addition3': dataset['train']['usage']\n",
        "\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data_for_df)\n",
        "df"
      ],
      "metadata": {
        "id": "jMRreJ0KKi2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# seeing the unique values for gender and category columns\n",
        "display(df['gender'].value_counts())\n",
        "display(df['category'].value_counts())"
      ],
      "metadata": {
        "id": "DUCyI69XP76L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# selecting only the values 'men' and 'women' for the gender column\n",
        "# selecting only the value 'apparel' for the category column\n",
        "df = df.loc[((df['gender'] == 'Men') | (df['gender'] == 'Women')),:]\n",
        "df = df.loc[(df['category'] == 'Apparel'),:]"
      ],
      "metadata": {
        "id": "cQlTZ6hfLHDo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(df['gender'].value_counts())\n",
        "display(df['category'].value_counts())"
      ],
      "metadata": {
        "id": "NWBH_U7jQ-Sa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# changing 'gender' class labels to numerical categories\n",
        "map_to_num = {'Men': 0, 'Women': 1}\n",
        "df['gender'] = df['gender'].map(map_to_num)\n",
        "df"
      ],
      "metadata": {
        "id": "aEn0-aCfojk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = df['gender'].tolist()\n",
        "\n",
        "# reducing the size of the dataframe, since decision trees can work with less data\n",
        "# and this would make analysis easier\n",
        "df_reduced, _, = train_test_split(df,test_size=0.9, random_state= 42, stratify=y)\n",
        "df_reduced"
      ],
      "metadata": {
        "id": "0bgokYe3nXWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df_reduced\n",
        "display(df['gender'].value_counts())"
      ],
      "metadata": {
        "id": "1qO4a7Clo9FV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# combining some columns to make a single description for each product\n",
        "\n",
        "df['text'] = df['text'] + \" \" + df['addition2'] + \" \" + df['addition3']\n",
        "df"
      ],
      "metadata": {
        "id": "MW4KXFfsKrzQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# delete the redundant columns now\n",
        "df.drop(['category', 'addition2', 'addition3'], axis = 1, inplace = True)\n",
        "df"
      ],
      "metadata": {
        "id": "NCZjZQvB1O5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_list = df['text'].tolist()\n",
        "id_list = df['id'].tolist()\n",
        "dictionary = dict(zip(id_list, text_list))\n",
        "\n",
        "words = ['men', 'women', 'mens', 'womens', 'man', 'woman', 'Men', 'Women', 'Mens', 'Womens', 'Man', 'Woman', 'Men\\'s', 'Women\\'s', 'men\\'s', 'women\\'s']\n",
        "\n",
        "for key, value in dictionary.items():\n",
        "  for each_word in value.split():\n",
        "    if each_word in words:\n",
        "      new_text = value.replace(each_word,'')\n",
        "      dictionary[key] = new_text"
      ],
      "metadata": {
        "id": "aD82ezmGX9N8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gender_list = df['gender'].tolist()\n",
        "\n",
        "temp_dictionary = {\n",
        "    'id': dictionary.keys(),\n",
        "    'text': dictionary.values(),\n",
        "    'gender': gender_list\n",
        "}"
      ],
      "metadata": {
        "id": "FY0F94Gjamcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame.from_dict(temp_dictionary)\n",
        "df"
      ],
      "metadata": {
        "id": "vnZswyIJa9bM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.sort_values(by=[\"id\"])\n",
        "df"
      ],
      "metadata": {
        "id": "6aw_Vc0-6mFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text data feature extraction"
      ],
      "metadata": {
        "id": "MF72KS5WjjrB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting dataset into features (Feature vector - X) and target variables (Labels- Y)\n",
        "# Feature Vector - X\n",
        "X = df[['id','text']]\n",
        "\n",
        "# saving this becasuse it has the preprocessed text which is needed later for explanation\n",
        "X_for_text_explanation = X\n",
        "X_for_text_explanation.to_csv(\"X_for_text_explanation.csv\")\n",
        "\n",
        "# Target Variables- Y\n",
        "y = df['gender'].tolist()\n",
        "\n",
        "display(X)\n",
        "display(y)"
      ],
      "metadata": {
        "id": "-k1gG9758LO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device =  'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "id": "d_t7XDmNiQ5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the clothing text model\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Showroom/clothing_subcategory_classifier\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"Showroom/clothing_subcategory_classifier\")\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "E-xQ5KCeRnf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# just running one sentence to get all classes/features the clothing text model has\n",
        "feature_list = []\n",
        "first_sent = X['text'][0]\n",
        "\n",
        "inputs = tokenizer(first_sent, return_tensors=\"pt\").to(device)\n",
        "outputs = model(**inputs)\n",
        "logits = outputs.logits\n",
        "\n",
        "topk = torch.topk(logits, 8).indices # out of index error with numbers>8 so this model calculates 8 features\n",
        "for each_value in topk[0]:\n",
        "  feature_list.append(model.config.id2label[each_value.item()])\n",
        "\n",
        "display(feature_list)"
      ],
      "metadata": {
        "id": "Er8EoS8mR060"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df = pd.DataFrame(columns = ['id', feature_list[0], feature_list[1], feature_list[2], feature_list[3], feature_list[4],\n",
        "           feature_list[5], feature_list[6], feature_list[7]])\n",
        "new_df.head()"
      ],
      "metadata": {
        "id": "SH6kCESTZrpa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the values for 8 features for all products now (as calculated above,\n",
        "# the pre-trained model calculates values for 8 fixed features)\n",
        "all_sents = X['text'].tolist()\n",
        "\n",
        "all_sents= all_sents\n",
        "n = len(feature_list)\n",
        "all_lists = [[] for _ in range(n)]\n",
        "\n",
        "for each_sent in tqdm(all_sents):\n",
        "  temp_dictionary = {}\n",
        "  inputs = tokenizer(each_sent, return_tensors=\"pt\").to(device)\n",
        "  outputs = model(**inputs)\n",
        "  logits = outputs.logits\n",
        "  probs = logits.softmax(dim=1) # we can take the softmax to get the label probabilities\n",
        "\n",
        "  topk = torch.topk(logits, 8).indices # out of index error with numbers>8 so this model calculates 8 features\n",
        "  for each_value in topk[0]:\n",
        "    temp_dictionary[model.config.id2label[each_value.item()]] = probs[0][each_value.item()].item()\n",
        "\n",
        "  new_df = new_df.append(temp_dictionary, ignore_index = True)"
      ],
      "metadata": {
        "id": "PYAzI59DTCsv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idl = X['id'].tolist()\n",
        "new_df['id'] = idl\n",
        "new_df"
      ],
      "metadata": {
        "id": "nm9w9tffBFle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save idl in a csv file\n",
        "id_df = pd.DataFrame(idl, columns=['id'])\n",
        "id_df.to_csv('id.csv')\n",
        "\n",
        "id_df"
      ],
      "metadata": {
        "id": "EccCCYuQG3Fx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = new_df\n",
        "X.drop(['id'], axis = 1, inplace = True)\n",
        "# saving only the text features X\n",
        "X.to_csv('text_features.csv')\n",
        "X"
      ],
      "metadata": {
        "id": "O2a3xocOGXno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = pd.DataFrame(y, columns = ['labels'])\n",
        "\n",
        "# saving the labels\n",
        "y.to_csv('labels.csv')\n",
        "y"
      ],
      "metadata": {
        "id": "axchFA2LNzXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FOR EXAMPLES FOR PPT\n",
        "X_text = X\n",
        "y_text = y"
      ],
      "metadata": {
        "id": "rF4jih67br-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image data feature extraction"
      ],
      "metadata": {
        "id": "-XxdUPi_-Ng8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opendatasets"
      ],
      "metadata": {
        "id": "ZfRiTXK5QaEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import opendatasets as od\n",
        "import pandas as pd\n",
        "\n",
        "# use your api key for the step below\n",
        "\n",
        "od.download(\"https://www.kaggle.com/datasets/paramaggarwal/fashion-product-images-small\")"
      ],
      "metadata": {
        "id": "ll0K2-Fd7-pe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoImageProcessor, ResNetForImageClassification, AutoModelForImageClassification, AutoFeatureExtractor\n",
        "import torch\n",
        "from PIL import Image\n",
        "\n",
        "temp_idl = idl\n",
        "\n",
        "temp_list_of_dictionaries = []\n",
        "temp_dictionary = {}\n",
        "\n",
        "# get the model for image feature extraction\n",
        "extractor = AutoFeatureExtractor.from_pretrained(\"aalonso-developer/vit-base-clothing-leafs-example-full-simple_highres\")\n",
        "model = AutoModelForImageClassification.from_pretrained(\"aalonso-developer/vit-base-clothing-leafs-example-full-simple_highres\")\n",
        "model = model.to(device)\n",
        "\n",
        "# calculate the features for all images\n",
        "\n",
        "for i in tqdm(range(len(temp_idl))):\n",
        "\n",
        "  temp_dictionary = {}\n",
        "  image_name = \"fashion-product-images-small/images/\"+str(temp_idl[i])+\".jpg\"\n",
        "  image = Image.open(image_name)\n",
        "  # im = np.asarray(image.convert('RGB')).astype('float32') / 255.0\n",
        "  im = np.asarray(image.convert('RGB'))\n",
        "\n",
        "  inputs = extractor(im, return_tensors=\"pt\").to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "      logits = model(**inputs).logits\n",
        "\n",
        "  probs = logits.softmax(dim=1) # we can take the softmax to get the label probabilities\n",
        "  topk = torch.topk(logits, 2).indices\n",
        "  for each_value in topk[0]:\n",
        "    # print(\"Prediciton: \", model.config.id2label[each_value.item()])\n",
        "    # print(\"Probability: \", probs[0][each_value.item()].item())\n",
        "    temp_dictionary[model.config.id2label[each_value.item()]] = probs[0][each_value.item()].item()\n",
        "\n",
        "  temp_list_of_dictionaries.append(temp_dictionary)\n"
      ],
      "metadata": {
        "id": "AOenoASFNytm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_image = pd.DataFrame(temp_list_of_dictionaries)\n",
        "X_image = X_image.fillna(0)\n",
        "X_image"
      ],
      "metadata": {
        "id": "zwuSSuGJW8-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save the image features separately\n",
        "X_image.to_csv('image_features.csv')"
      ],
      "metadata": {
        "id": "8fBAvjrvd_fC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_all_features = pd.concat([X_text, X_image], axis=1)\n",
        "X_all_features"
      ],
      "metadata": {
        "id": "U3TKCRS9eFdN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save all feature\n",
        "X_all_features.to_csv('all_features.csv')"
      ],
      "metadata": {
        "id": "hM5nHx7Feshy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download all result files"
      ],
      "metadata": {
        "id": "J-Yn1pnEHkmw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"text_features.csv\")\n",
        "files.download(\"image_features.csv\")\n",
        "files.download(\"all_features.csv\")\n",
        "files.download(\"labels.csv\")\n",
        "files.download(\"id.csv\")\n",
        "files.download(\"X_for_text_explanation.csv\")"
      ],
      "metadata": {
        "id": "YUFbNkOAx1I0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}