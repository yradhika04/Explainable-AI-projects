{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "vRrnZkYu6rq8",
        "n4VD_5sW6jsx",
        "xxJl8da0duh9",
        "sjiyDi68-nKo",
        "EidlAe5-WW3b",
        "wIe83p1L_FDB"
      ],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Library requirements"
      ],
      "metadata": {
        "id": "vRrnZkYu6rq8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers SentencePiece accelerate evaluate sacrebleu"
      ],
      "metadata": {
        "id": "eCUAD7Sodz66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from evaluate import load\n",
        "from google.colab import files\n",
        "import sklearn"
      ],
      "metadata": {
        "id": "NQzfEOZS5qrW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reading and processing data"
      ],
      "metadata": {
        "id": "n4VD_5sW6jsx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# reading the validation split\n",
        "\n",
        "# reading more than 100 samples to have some extra samples\n",
        "# while prompting the model with few-shot prompting"
      ],
      "metadata": {
        "id": "YtPMzPumoqMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WCyjRVejw5m-"
      },
      "outputs": [],
      "source": [
        "df_val_qa = pd.read_json('Data/aokvqa_v1p0_val.json')\n",
        "df_val_qa.iloc[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_val_qa_102 = df_val_qa.sample(n=102, random_state=33)\n",
        "df_val_qa_102.sort_values(by=[\"image_id\"], inplace = True)\n",
        "df_val_qa_102\n"
      ],
      "metadata": {
        "id": "0NeOvVOIDrSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_val_qa_102.to_csv(\"all_data.csv\")\n",
        "df_val_qa_102['image_id'].to_csv(\"image_ids.csv\")\n",
        "image_ids_list = df_val_qa_102['image_id'].tolist()"
      ],
      "metadata": {
        "id": "gCHSEyAeFM92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# getting the image captions for all the questions in the validation set\n",
        "# we are using image captions directly here instead of working with the images\n",
        "# and extracting features/information from them\n",
        "\n",
        "with open(\"Data/captions_val2017.json\",'r') as f:\n",
        "    data = json.loads(f.read())\n",
        "\n",
        "df_val_captions = pd.json_normalize(data[\"annotations\"])\n",
        "\n",
        "df_val_captions"
      ],
      "metadata": {
        "id": "gz0KTLosBiZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# further filtering down the image captions for only the 102 samples we have selected\n",
        "\n",
        "df_val_captions_102 = df_val_captions[(df_val_captions['image_id'].isin(image_ids_list))]\n",
        "df_val_captions_102"
      ],
      "metadata": {
        "id": "JVLcvQpKZSGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# each image has multiple possible captions, so only selecting one for each\n",
        "df_val_captions_102.drop_duplicates(subset=['image_id'], inplace = True)\n",
        "df_val_captions_102.sort_values(by=[\"image_id\"], inplace = True)\n",
        "df_val_captions_102"
      ],
      "metadata": {
        "id": "e_N0SWhAaFFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_val_qa_2, df_val_qa_100 = df_val_qa_102.iloc[:2, :], df_val_qa_102.iloc[2:, :]\n",
        "df_val_captions_2, df_val_captions_100 = df_val_captions_102.iloc[:2, :], df_val_captions_102.iloc[2:, :]"
      ],
      "metadata": {
        "id": "RiKdqJQQMATq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# saving the questions and captions\n",
        "temp_data = df_val_qa_100[['image_id', 'question']]\n",
        "temp_images = df_val_captions_100[['caption']]\n",
        "temp_concat = pd.concat([temp_data.reset_index(drop=True), temp_images.reset_index(drop=True)], axis=1)\n",
        "temp_concat.to_csv(\"questions_and_captions.csv\")"
      ],
      "metadata": {
        "id": "4oE35PXFdRFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the dataset has multiple choice answers or direct answers for the questions\n",
        "# we use only direct answers for our task\n",
        "\n",
        "truth_answers_list = []\n",
        "for i in range(df_val_qa_100.shape[0]):\n",
        "  truth_answers_list.append(df_val_qa_100.iloc[i][\"direct_answers\"])"
      ],
      "metadata": {
        "id": "RdJePORK7lL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# getting all the rationales/explanations for the answers (of our selected\n",
        "# questions) from the dataset\n",
        "\n",
        "truth_rationales_list = []\n",
        "for i in range(df_val_qa_100.shape[0]):\n",
        "  truth_rationales_list.append(df_val_qa_100.iloc[i][\"rationales\"])"
      ],
      "metadata": {
        "id": "VzeBw7JYdAq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LLM model and prompting strategies"
      ],
      "metadata": {
        "id": "xxJl8da0duh9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "device"
      ],
      "metadata": {
        "id": "eqaf3ieoeGAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# getting the model and its tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-large\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-large\").to(device)"
      ],
      "metadata": {
        "id": "EqsMylC0McGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Writing a prompt for getting the answers for each question\n",
        "\n",
        "# This is a few shot prompt, i.e., the model gets a few examples of questions\n",
        "# and answers. Then we add our question and its image context to this prompt\n",
        "# and ask the model to generate an answer\n",
        "\n",
        "# Additionally, through trial-and-error, it was found that the model\n",
        "# performs better when the prompts start with a \"please\"\n",
        "\n",
        "# Further analysis about this is included in the Project Report,\n",
        "# under section 6.2.1 \"Prompting strategy\", pg. 7\n",
        "\n",
        "answer_task = \"Please answer the question given an image context. Use these examples for help. \\n\\n\"\n",
        "example1 = \"Example 1 \\n\" + \"Image context: \" + df_val_captions_2.iloc[0][\"caption\"] + \"\\n\" + \"Question: \" + df_val_qa_2.iloc[0][\"question\"] + \"\\n\" + \"Answer: \"+ df_val_qa_2.iloc[0][\"choices\"][df_val_qa_2.iloc[0]['correct_choice_idx']] + \"\\n\\n\"\n",
        "example2 = \"Example 2 \\n\" + \"Image context: \" + df_val_captions_2.iloc[1][\"caption\"] + \"\\n\" + \"Question: \" + df_val_qa_2.iloc[1][\"question\"] + \"\\n\" + \"Answer: \"+ df_val_qa_2.iloc[1][\"choices\"][df_val_qa_2.iloc[1]['correct_choice_idx']] +\"\\n\\n\"\n",
        "\n",
        "fixed_string = answer_task + example1 + example2\n",
        "print(fixed_string)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDIuq8Qz3doK",
        "outputId": "9106f4e3-2d16-4119-8628-c641ed37104f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please answer the question given an image context. Use these examples for help. \n",
            "\n",
            "Example 1 \n",
            "Image context: A bunch of bananas sitting on top of a wooden table.\n",
            "Question: What treat can be made with this fruit and ice cream?\n",
            "Answer: banana split\n",
            "\n",
            "Example 2 \n",
            "Image context: A pan filled with onions sitting next to a pan of stew.\n",
            "Question: The reddish-brown food in the further bowl is what type of food?\n",
            "Answer: meat\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = df_val_qa_100.shape[0]\n",
        "# n = 2\n",
        "prediction_answers_list = []\n",
        "\n",
        "for i in tqdm(range(n)):\n",
        "\n",
        "  input_text = fixed_string + \"Image context: \" + df_val_captions_100.iloc[i][\"caption\"] + \"Question: \" + df_val_qa_100.iloc[i][\"question\"] + \"Answer: \"\n",
        "  input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(device)\n",
        "\n",
        "  outputs = model.generate(input_ids)\n",
        "  prediction_answers_list.append(tokenizer.decode(outputs[0][1:-1]))\n",
        "\n",
        "prediction_answers_list\n"
      ],
      "metadata": {
        "id": "nN6fUrlVdu1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Writing a prompt for getting the rationales for each answer that the model\n",
        "# generates\n",
        "\n",
        "# This is a zero-shot prompt, only the instruction is given to the model without\n",
        "# any examples\n",
        "\n",
        "\n",
        "# selected one rationale from the dataset for each sample (the dataset has 3 for\n",
        "# each input)\n",
        "\n",
        "rationale_task = \"Please generate explanations for the given answer. \\n\\n\"\n",
        "\n",
        "fixed_string = rationale_task\n",
        "print(fixed_string)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKcg6t9UNy00",
        "outputId": "bca67480-e021-4373-ebeb-6e934b92c073"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please generate explanations for the given answer. \n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = df_val_qa_100.shape[0]\n",
        "prediction_rationales_list = []\n",
        "\n",
        "for i in tqdm(range(n)):\n",
        "\n",
        "  each_prediction = \"Image context: \" + df_val_captions_100.iloc[i][\"caption\"] + \"\\n\" + \"Question: \" + df_val_qa_100.iloc[i][\"question\"] + \"\\n\" + \"Answer: \"+ prediction_answers_list[i] + \"\\n\" + \"Explanation: \" \"\\n\\n\"\n",
        "  input_text = fixed_string + each_prediction\n",
        "\n",
        "  input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(device)\n",
        "\n",
        "  outputs = model.generate(input_ids)\n",
        "  prediction_rationales_list.append(tokenizer.decode(outputs[0][1:-1]))\n",
        "\n",
        "prediction_rationales_list\n"
      ],
      "metadata": {
        "id": "dzLqAFiab_yI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results and evaluation metrics"
      ],
      "metadata": {
        "id": "sjiyDi68-nKo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# saving all the true and predicted answers and explanations\n",
        "\n",
        "results_dictionary = {'image_ids': image_ids_list[2:],\n",
        "                      'True answers': truth_answers_list,\n",
        "                      'Predicted answer': prediction_answers_list,\n",
        "                      'True rationales': truth_rationales_list,\n",
        "                      'Predicted rationale': prediction_rationales_list}\n",
        "\n",
        "df_results = pd.DataFrame(results_dictionary)\n",
        "df_results"
      ],
      "metadata": {
        "id": "OVENralrhmyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_results.to_csv('answers_and_explanations.csv')"
      ],
      "metadata": {
        "id": "26WqNyeShrZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating the meteor scores for the model generated answers\n",
        "\n",
        "meteor = load(\"meteor\")\n",
        "answers_results = meteor.compute(predictions=prediction_answers_list, references=truth_answers_list)\n",
        "print(\"The METEOR score for the model's answers\", answers_results)"
      ],
      "metadata": {
        "id": "GhNH6WlJ8e3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'This is the METEOR score for the answers'\n",
        "with open('final_scores.csv','w') as f:\n",
        "    f.write(text)\n",
        "    f.write(\"\\n\"+str(answers_results)+\"\\n\")\n",
        "    f.write(\"\\n\")"
      ],
      "metadata": {
        "id": "V8RgNMrO0kUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating the meteor scores for the model generated rationales/explanations\n",
        "\n",
        "predictions_results = meteor.compute(predictions=prediction_rationales_list, references=truth_rationales_list)\n",
        "print(\"The METEOR score for the model's explanations\", predictions_results)"
      ],
      "metadata": {
        "id": "bzCDHd-WX6ce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'This is the METEOR score for the explanations'\n",
        "with open('final_scores.csv','a+') as f:\n",
        "    f.write(text)\n",
        "    f.write(\"\\n\"+str(predictions_results)+\"\\n\")\n",
        "    f.write(\"\\n\")"
      ],
      "metadata": {
        "id": "8rY_ExaA1CBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating the sacreblue scores for the model generated answers\n",
        "\n",
        "sacrebleu = load(\"sacrebleu\")\n",
        "answers_results = sacrebleu.compute(predictions=prediction_answers_list, references=truth_answers_list)\n",
        "print(\"The sacrebleu score for the model's answers\", answers_results)"
      ],
      "metadata": {
        "id": "vMMLV8_4_UGj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'This is the sacrebleu score for the answers'\n",
        "with open('final_scores.csv','a+') as f:\n",
        "    f.write(text)\n",
        "    f.write(\"\\n\"+str(answers_results)+\"\\n\")\n",
        "    f.write(\"\\n\")"
      ],
      "metadata": {
        "id": "YmJN0Q7L_lRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating the sacreblue score for the model generated rationales/explanations\n",
        "\n",
        "predictions_results = sacrebleu.compute(predictions=prediction_rationales_list, references=truth_rationales_list)\n",
        "print(\"The sacrebleu score for the model's explanations\", predictions_results)"
      ],
      "metadata": {
        "id": "rbRUplnd_u4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'This is the sacrebleu score for the explanations'\n",
        "with open('final_scores.csv','a+') as f:\n",
        "    f.write(text)\n",
        "    f.write(\"\\n\"+str(predictions_results)+\"\\n\")\n",
        "    f.write(\"\\n\")"
      ],
      "metadata": {
        "id": "M-VYuhq1_vWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Interannotator agreement"
      ],
      "metadata": {
        "id": "EidlAe5-WW3b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Details on the annotation scheme can be found in the Project Report under\n",
        "# section 6.2.2 \"Annotation scheme\", pg. 8\n",
        "\n",
        "# annotator 1 goodness scores for all the explanations\n",
        "y1_goodness = [1,1,1,0,0,1,0,0,1,1,0,0,1,0,0,1,0,0,1,1,0,1,1,1,0,1,0,0,1,0,0,1,0,0,0,0,1,1,1,1,0,1,0,0,1,0,0,0,0,0,1,1,0,0,1,0,0,0,1,1,1,0,1,1,0,0,1,0,1,0,1,1,0,1,0,0,0,1,0,0,1,0,0,0,1,0,0,0,0,0,0,0,1,0,1,1,0,1,1,1]\n",
        "\n",
        "# annotator 2 goodness scores for all the explanations\n",
        "y2_goodness = [1,0,1,0,0,0,0,1,1,1,0,0,0,0,0,1,0,0,1,1,1,1,1,1,0,1,0,0,1,0,0,0,0,0,0,0,1,1,1,0,0,1,1,0,1,0,0,0,0,0,1,1,0,0,0,1,1,0,1,1,1,0,1,1,1,1,1,0,1,0,0,1,0,1,0,0,1,1,0,0,1,0,0,0,1,0,1,0,0,0,0,0,1,0,0,0,0,1,1,1]"
      ],
      "metadata": {
        "id": "tRfoQbeLYnDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculating annotator agreement value using cohen's kappa\n",
        "\n",
        "iaa_goodness = sklearn.metrics.cohen_kappa_score(y1_goodness, y2_goodness)\n",
        "iaa_goodness"
      ],
      "metadata": {
        "id": "Vgt2XtM6Wboi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'This is the inter-annotator agreement score for the goodness (The explanation is satisfying)'\n",
        "with open('final_scores.csv','a+') as f:\n",
        "    f.write(text)\n",
        "    f.write(\"\\n\"+str(iaa_goodness)+\"\\n\")\n",
        "    f.write(\"\\n\")"
      ],
      "metadata": {
        "id": "N_rGHoQkuJpc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# annotator 1 satisfaction scores for all the explanations\n",
        "y1_satisfaction = [5,2,4,4,1,5,2,1,5,5,1,1,3,1,1,5,1,2,5,3,2,4,5,3,2,4,2,2,5,2,3,5,1,1,3,1,3,4,3,5,2,5,2,1,4,1,2,1,3,3,4,5,1,1,5,3,3,3,5,4,5,1,4,5,2,3,5,1,2,2,5,5,1,3,2,1,3,5,1,3,4,2,1,1,5,2,2,2,3,3,2,3,4,2,4,5,2,3,4,4]\n",
        "\n",
        "# annotator 2 satisfaction scores for all the explanations\n",
        "y2_satisfaction = [5,2,3,2,1,2,1,3,5,4,1,1,2,3,3,5,1,2,5,4,3,4,4,5,3,5,2,2,5,2,1,2,2,2,2,1,3,3,4,3,1,5,4,1,4,1,2,2,1,3,3,4,1,1,2,2,2,1,5,4,4,2,5,5,4,5,5,2,5,3,4,3,2,4,2,1,3,4,1,2,5,1,1,2,5,2,5,2,1,2,2,3,3,2,3,1,1,5,4,4]"
      ],
      "metadata": {
        "id": "ObKoOqlEZXaT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculating annotator agreement value using cohen's kappa\n",
        "\n",
        "iaa_satisfaction = sklearn.metrics.cohen_kappa_score(y1_satisfaction, y2_satisfaction)\n",
        "iaa_satisfaction"
      ],
      "metadata": {
        "id": "qtyiD1F8ZbQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'This is the inter-annotator agreement score for the satisfaction (The explanation is satisfying)'\n",
        "with open('final_scores.csv','a+') as f:\n",
        "    f.write(text)\n",
        "    f.write(\"\\n\"+str(iaa_satisfaction)+\"\\n\")\n",
        "    f.write(\"\\n\")"
      ],
      "metadata": {
        "id": "eMtjMNloukOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download results files"
      ],
      "metadata": {
        "id": "wIe83p1L_FDB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "files.download('questions_and_captions.csv')\n",
        "files.download('image_ids.csv')\n",
        "files.download('answers_and_explanations.csv')\n",
        "files.download('final_scores.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Czo3RoWz_HGA",
        "outputId": "015f0a20-9d19-481f-c4f1-c2edc268cf3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5fc4a5bf-abc9-41f0-99d9-2240c6e0e255\", \"questions_and_captions.csv\", 10958)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8c5f4a53-ff53-4efc-bfa8-d3181f01781a\", \"image_ids.csv\", 1117)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6256ccfe-1ebf-4b3a-915c-665b71948877\", \"answers_and_explanations.csv\", 38063)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_89321ebf-aa50-4820-a8e1-9605147c2831\", \"final_scores.csv\", 927)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}