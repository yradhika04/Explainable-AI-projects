{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "tUWx2KY7_jx0",
        "LXJnvV3S89Sx",
        "i_dYW27V-zss",
        "RmtQvNwW-8th",
        "SF5DNr-SI_hR",
        "XpG9u6VzJB_m",
        "E2W60LcOC8Pv",
        "m_TRaxfri-xY",
        "8EUQroV3B9VR",
        "iRwxxINGSRZ5",
        "v2msXZRzVBYO",
        "pM2GVWHydy32"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Library requirements"
      ],
      "metadata": {
        "id": "tUWx2KY7_jx0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets\n",
        "!pip install opendatasets"
      ],
      "metadata": {
        "id": "Y2ltUdsTVgfV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import loadtxt\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import loadtxt\n",
        "import matplotlib.pyplot as plt\n",
        "from xgboost import plot_importance, plot_tree\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from datasets import load_dataset\n",
        "from tqdm import tqdm\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "from transformers import AutoModelForImageClassification, AutoFeatureExtractor\n",
        "from PIL import Image\n",
        "import opendatasets as od\n",
        "from PIL import Image, ImageFilter, ImageChops, ImageEnhance, ImageOps\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "KQPklr0hTXfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGBoost with text features"
      ],
      "metadata": {
        "id": "LXJnvV3S89Sx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# reading all the text features\n",
        "X_text_features = pd.read_csv(\"feature_arrays/text_features.csv\")\n",
        "y = pd.read_csv(\"feature_arrays/labels.csv\")"
      ],
      "metadata": {
        "id": "voSohZmZ9GIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_text_features.drop(['Unnamed: 0'], axis = 1, inplace = True)\n",
        "y.drop(['Unnamed: 0'], axis = 1, inplace = True)\n",
        "display(X_text_features)\n",
        "display(y)"
      ],
      "metadata": {
        "id": "IHR7ZoFk0_gf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting dataset\n",
        "# Training - 70%\n",
        "# Test - 30%\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_text_features, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "y_actual = y_test\n",
        "\n",
        "print(\"X_train: \", X_train.shape)\n",
        "print(\"X_test: \", X_test.shape)\n",
        "\n",
        "print(\"y_train: \", y_train.shape)\n",
        "print(\"y_test: \", y_test.shape)\n",
        "\n",
        "display(X_train)\n",
        "display(y_train)\n",
        "display(X_test)\n",
        "display(y_test)"
      ],
      "metadata": {
        "id": "6BR_uF8I9DPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training a and testing a model with only the text features\n",
        "\n",
        "# define and train model\n",
        "model = XGBClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# then predict on test data\n",
        "y_pred = model.predict(X_test)\n",
        "predictions = [round(value) for value in y_pred]\n",
        "\n",
        "y_for_texts = predictions\n",
        "\n",
        "# calculate accuracy\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(\"Accuracy:\", (accuracy * 100.0))"
      ],
      "metadata": {
        "id": "pRi0nF1r9BUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'This is the accuracy score for just the text features'\n",
        "with open('evaluation_results.csv','w') as f:\n",
        "    f.write(text)\n",
        "    f.write(\"\\n\"+str(accuracy)+\"\\n\")\n",
        "    f.write(\"\\n\")"
      ],
      "metadata": {
        "id": "O9oV-aJk7Uyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting the confusion matrix\n",
        "ConfusionMatrixDisplay.from_estimator(model, X_test, y_test)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YCA_zFYSR6a6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the feature importance values\n",
        "sorted_idx = model.feature_importances_.argsort()\n",
        "plt.figure(figsize=(6,8))\n",
        "plt.barh(X_train.columns[sorted_idx], model.feature_importances_[sorted_idx])\n",
        "plt.xlabel(\"Feature Importance\")"
      ],
      "metadata": {
        "id": "G_n-rOWc2lQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# built in function of XGBoost for feature importance\n",
        "plot_importance(model)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "L1CLEBUN23vG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGBoost with image features"
      ],
      "metadata": {
        "id": "i_dYW27V-zss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# read all the image features\n",
        "X_image_features = pd.read_csv(\"feature_arrays/image_features.csv\")\n",
        "X_image_features.drop(['Unnamed: 0'], axis = 1, inplace = True)\n",
        "X_image_features"
      ],
      "metadata": {
        "id": "n9hslV2v-8Cc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting dataset\n",
        "# Training - 70%\n",
        "# Test - 30%\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_image_features, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "print(\"X_train: \", X_train.shape)\n",
        "print(\"X_test: \", X_test.shape)\n",
        "\n",
        "print(\"y_train: \", y_train.shape)\n",
        "print(\"y_test: \", y_test.shape)\n",
        "\n",
        "display(X_train)\n",
        "display(y_train)\n",
        "display(X_test)\n",
        "display(y_test)"
      ],
      "metadata": {
        "id": "W4John1wS-nt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training and testing a model on just the image features\n",
        "\n",
        "# define and train model\n",
        "model = XGBClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# then predict on test data\n",
        "y_pred = model.predict(X_test)\n",
        "predictions = [round(value) for value in y_pred]\n",
        "y_for_images = predictions\n",
        "\n",
        "# calculate accuracy\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(\"Accuracy:\", (accuracy * 100.0))"
      ],
      "metadata": {
        "id": "MA4dmgluTBoD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'This is the accuracy score for just the image features'\n",
        "with open('evaluation_results.csv','a+') as f:\n",
        "    f.write(text)\n",
        "    f.write(\"\\n\"+str(accuracy)+\"\\n\")\n",
        "    f.write(\"\\n\")"
      ],
      "metadata": {
        "id": "D1NY7kgO7vEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting the confusion matrix\n",
        "ConfusionMatrixDisplay.from_estimator(model, X_test, y_test)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "n4CPq8hIS_v7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the feature importance values\n",
        "sorted_idx = model.feature_importances_.argsort()\n",
        "plt.figure(figsize=(6,8))\n",
        "plt.barh(X_train.columns[sorted_idx], model.feature_importances_[sorted_idx])\n",
        "plt.xlabel(\"Feature Importance\")"
      ],
      "metadata": {
        "id": "lFI2Q9lt3nAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# built in function of XGBoost for feature importance\n",
        "plot_importance(model)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "H9bV3ymQ3yfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGBoost with both features"
      ],
      "metadata": {
        "id": "RmtQvNwW-8th"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# read all the features (text+image combined)\n",
        "X_all_features = pd.read_csv(\"feature_arrays/all_features.csv\")\n",
        "X_all_features.drop(['Unnamed: 0'], axis = 1, inplace = True)\n",
        "X_all_features"
      ],
      "metadata": {
        "id": "wtBvKmX8THOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting dataset\n",
        "# Training - 70%\n",
        "# Test - 30%\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_all_features, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "print(\"X_train: \", X_train.shape)\n",
        "print(\"X_test: \", X_test.shape)\n",
        "\n",
        "print(\"y_train: \", y_train.shape)\n",
        "print(\"y_test: \", y_test.shape)\n",
        "\n",
        "display(X_train)\n",
        "display(y_train)\n",
        "display(X_test)\n",
        "display(y_test)"
      ],
      "metadata": {
        "id": "dld23bYrTNOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training and testing a model with both text and image features\n",
        "\n",
        "# define and train model\n",
        "model = XGBClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# then predict on test data\n",
        "y_pred = model.predict(X_test)\n",
        "predictions = [round(value) for value in y_pred]\n",
        "y_for_both = predictions\n",
        "\n",
        "# calculate accuracy\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(\"Accuracy:\", (accuracy * 100.0))"
      ],
      "metadata": {
        "id": "iqvFdzUZTOoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'This is the accuracy score for both text + image features'\n",
        "with open('evaluation_results.csv','a+') as f:\n",
        "    f.write(text)\n",
        "    f.write(\"\\n\"+str(accuracy)+\"\\n\")\n",
        "    f.write(\"\\n\")"
      ],
      "metadata": {
        "id": "hvkqXzb778DQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting the confusion matrix\n",
        "ConfusionMatrixDisplay.from_estimator(model, X_test, y_test)\n",
        "plt.savefig('confusionmatrix.png', dpi=1000)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bytnUpN1TCYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_idx = model.feature_importances_.argsort()\n",
        "plt.figure(figsize=(6,8))\n",
        "plt.barh(X_train.columns[sorted_idx], model.feature_importances_[sorted_idx])\n",
        "plt.xlabel(\"Feature Importance\")\n",
        "plt.savefig(\"feature_imp_sorted.png\", bbox_inches=\"tight\", dpi=1000)"
      ],
      "metadata": {
        "id": "RxaiVpTKL4cR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_feature_names = []\n",
        "for i in range(len(X_train.columns)):\n",
        "  if model.feature_importances_[i] > 0.060:\n",
        "    top_feature_names.append(X_train.columns[i])\n",
        "\n",
        "top_feature_names = np.array(top_feature_names)\n",
        "\n",
        "print(top_feature_names)"
      ],
      "metadata": {
        "id": "m0gbulmPqT1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# built in function of XGBoost for feature importance\n",
        "plot_importance(model)\n",
        "plt.savefig('featureimp_xgboost.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iiTCzFM43uex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting the decision tree for the model with both features\n",
        "fig, ax = plt.subplots(1,1, figsize=(10,8), dpi=600)\n",
        "plot_tree(model, ax=ax)\n",
        "plt.savefig('decision_tree.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t5a2MK_0m47z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting correct samples"
      ],
      "metadata": {
        "id": "SF5DNr-SI_hR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "truth_list = y_test['labels'].tolist()"
      ],
      "metadata": {
        "id": "GYjjxDEnKRBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# getting index of correct samples in y_pred, then just choose 3 of those for explanation\n",
        "correct_samples = []\n",
        "\n",
        "for i in range(len(y_pred)):\n",
        "  if truth_list[i] == y_pred[i]:\n",
        "    correct_samples.append(i)\n",
        "\n",
        "correct_samples = correct_samples[4:7]\n",
        "\n",
        "# loop to see what is the label of these correct samples- 0 (men) or 1 (women)\n",
        "for i in range(len(correct_samples)):\n",
        "  print(truth_list[correct_samples[i]])\n",
        "\n",
        "print(correct_samples)"
      ],
      "metadata": {
        "id": "9wY0gJwaJIEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using above indices to get image ids from id.csv\n",
        "\n",
        "ids = pd.read_csv(\"feature_arrays/id.csv\")\n",
        "ids.drop(['Unnamed: 0'], axis = 1, inplace = True)\n",
        "\n",
        "correct_ids = []\n",
        "for i in range(len(correct_samples)):\n",
        "  correct_ids.append(ids.iloc[correct_samples[i]][0])\n",
        "\n",
        "print(correct_ids)"
      ],
      "metadata": {
        "id": "LFhYmFgG1QSV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read the text dataset file \"X_for_text_exaplanation\" and get the text of these three samples\n",
        "\n",
        "X_for_text_explanation = pd.read_csv(\"feature_arrays/X_for_text_explanation.csv\")\n",
        "X_for_text_explanation.drop(['Unnamed: 0'], axis = 1, inplace = True)\n",
        "\n",
        "all_sents = []\n",
        "\n",
        "for each_value in correct_samples:\n",
        "  # num = X_for_text_explanation[X_for_text_explanation['id']==each_value].index.values\n",
        "  all_sents.append(X_for_text_explanation.iloc[each_value][1])\n",
        "\n",
        "all_sents"
      ],
      "metadata": {
        "id": "27-5ZWRdRpLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use your api key for the step below\n",
        "\n",
        "od.download(\"https://www.kaggle.com/datasets/paramaggarwal/fashion-product-images-small\")"
      ],
      "metadata": {
        "id": "GlVXfevT1jTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_idl = correct_ids\n",
        "\n",
        "for i in tqdm(range(len(temp_idl))):\n",
        "\n",
        "  image_name = \"fashion-product-images-small/images/\"+str(temp_idl[i])+\".jpg\"\n",
        "  image = Image.open(image_name)\n",
        "  image.save(str(temp_idl[i])+\".png\")\n",
        "  print(image)\n"
      ],
      "metadata": {
        "id": "0pDTP9d0ZqWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the feature values for these three correctly classified samples\n",
        "for i in range(len(correct_samples)):\n",
        "  print(X_all_features.iloc[correct_samples[i]])"
      ],
      "metadata": {
        "id": "qwB7RGTPHQfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting incorrect samples"
      ],
      "metadata": {
        "id": "XpG9u6VzJB_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# getting index of incorrect samples in y_pred, then just choose 3 of those for explanation\n",
        "incorrect_samples = []\n",
        "\n",
        "for i in range(len(y_pred)):\n",
        "  if truth_list[i] != y_pred[i]:\n",
        "    incorrect_samples.append(i)\n",
        "\n",
        "incorrect_samples = [incorrect_samples[41],incorrect_samples[46]]\n",
        "\n",
        "# loop to see what is the label of these incorrect samples- 0 (men) or 1 (women)\n",
        "for i in range(len(incorrect_samples)):\n",
        "  print(truth_list[incorrect_samples[i]])\n",
        "\n",
        "incorrect_samples"
      ],
      "metadata": {
        "id": "RQhHzCOnL7XU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using above indices to get image ids from id.csv\n",
        "\n",
        "incorrect_ids = []\n",
        "for i in range(len(incorrect_samples)):\n",
        "  incorrect_ids.append(ids.iloc[incorrect_samples[i]][0])\n",
        "\n",
        "incorrect_ids"
      ],
      "metadata": {
        "id": "7p_bS38lRYI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read the text dataset file \"X_for_text_exaplanation\" and get the text of these three samples\n",
        "\n",
        "all_sents = []\n",
        "\n",
        "for each_value in incorrect_samples:\n",
        "  all_sents.append(X_for_text_explanation.iloc[each_value][1])\n",
        "\n",
        "all_sents"
      ],
      "metadata": {
        "id": "ATQ5aGjxYuJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# then download the image dataset and the image features of these three\n",
        "temp_idl = incorrect_ids\n",
        "\n",
        "for i in tqdm(range(len(temp_idl))):\n",
        "\n",
        "  image_name = \"fashion-product-images-small/images/\"+str(temp_idl[i])+\".jpg\"\n",
        "  image = Image.open(image_name)\n",
        "  image.save(str(temp_idl[i])+\".png\")\n",
        "  print(image)\n"
      ],
      "metadata": {
        "id": "B_ApB5k1ZRH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the feature values for these three correctly classified samples\n",
        "for i in range(len(incorrect_samples)):\n",
        "  print(X_all_features.iloc[incorrect_samples[i]])"
      ],
      "metadata": {
        "id": "PkwldkEhKC8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Counter-factual example type 1"
      ],
      "metadata": {
        "id": "E2W60LcOC8Pv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# checking some samples where either text/image alone was predicting the correct label\n",
        "# but the other label was predicting the wrong label\n",
        "# and combining them caused the overall model to predict the wrong label"
      ],
      "metadata": {
        "id": "fUb-hdizsUHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_mismatch1 = []\n",
        "all_mismatch2 = []\n",
        "l1 = []\n",
        "\n",
        "for i in range(len(y_for_texts)):\n",
        "  if y_for_texts[i] != y_for_images[i]:\n",
        "    all_mismatch1.append(i)\n",
        "\n",
        "for i in range(len(y_for_both)):\n",
        "  if y_for_both[i] != y_actual.iloc[i][0]:\n",
        "    all_mismatch2.append(i)\n",
        "\n",
        "list1 = list(set(all_mismatch1).intersection(set(all_mismatch2)))\n",
        "\n",
        "for i in range(len(list1)):\n",
        "  n = list1[i]\n",
        "  print(\"Mismatch sample index: \", n)\n",
        "  print(\"Actual label of the input at that index: \", y_actual.iloc[n][0])\n",
        "  print(\"Predicted label with both modalities: \", y_for_both[n])\n",
        "  print(\"Predicted label with just text: \", y_for_texts[n])\n",
        "  print(\"Predicted label with just image: \", y_for_images[n])\n",
        "  print(\"\\n\")"
      ],
      "metadata": {
        "id": "-8k-5ikg2egC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using above indices to get image ids from id.csv\n",
        "\n",
        "ids = pd.read_csv(\"feature_arrays/id.csv\")\n",
        "ids.drop(['Unnamed: 0'], axis = 1, inplace = True)\n",
        "\n",
        "mismatch_ids = []\n",
        "for i in range(len(list1)):\n",
        "  mismatch_ids.append(ids.iloc[list1[i]][0])\n",
        "\n",
        "mismatch_ids"
      ],
      "metadata": {
        "id": "q986y7N-C8Pw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read the text dataset file \"X_for_text_exaplanation\" and get the text of these three samples\n",
        "\n",
        "X_for_text_explanation = pd.read_csv(\"feature_arrays/X_for_text_explanation.csv\")\n",
        "X_for_text_explanation.drop(['Unnamed: 0'], axis = 1, inplace = True)\n",
        "\n",
        "all_sents = []\n",
        "\n",
        "for each_value in list1:\n",
        "  all_sents.append(X_for_text_explanation.iloc[each_value][1])\n",
        "\n",
        "all_sents"
      ],
      "metadata": {
        "id": "90YRty7IC8Px"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the feature values for these three correctly classified samples\n",
        "for i in range(len(list1)):\n",
        "  print(X_all_features.iloc[list1[i]])"
      ],
      "metadata": {
        "id": "yCuxE6EQa_oj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Counter-factual example type 2"
      ],
      "metadata": {
        "id": "m_TRaxfri-xY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# take one of the rows, remove some text from the input text and then give it to the model\n",
        "# see if there are any changes"
      ],
      "metadata": {
        "id": "CcA-ustjswMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "truth_list = y_test['labels'].tolist()"
      ],
      "metadata": {
        "id": "vdkPpd5zwpqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# getting index of correct samples in y_pred, then just choose 3 of those for explanation\n",
        "correct_samples = []\n",
        "y_test_one = []\n",
        "\n",
        "for i in range(len(y_pred)):\n",
        "  if truth_list[i] == y_pred[i]:\n",
        "    correct_samples.append(i)\n",
        "\n",
        "correct_samples = correct_samples[4:5]\n",
        "\n",
        "# loop to see what is the label of these correct samples- 0 (men) or 1 (women)\n",
        "for i in range(len(correct_samples)):\n",
        "  print(truth_list[correct_samples[i]])\n",
        "  y_test_one.append(truth_list[correct_samples[i]])\n",
        "\n",
        "print(correct_samples)\n",
        "\n",
        "\n",
        "# using above indices to get image ids from id.csv\n",
        "\n",
        "ids = pd.read_csv(\"feature_arrays/id.csv\")\n",
        "ids.drop(['Unnamed: 0'], axis = 1, inplace = True)\n",
        "\n",
        "correct_ids = []\n",
        "for i in range(len(correct_samples)):\n",
        "  correct_ids.append(ids.iloc[correct_samples[i]][0])\n",
        "\n",
        "print(correct_ids)"
      ],
      "metadata": {
        "id": "WAnfHV4SwpqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read the text dataset file \"X_for_text_exaplanation\" and get the text of these three samples\n",
        "\n",
        "X_for_text_explanation = pd.read_csv(\"feature_arrays/X_for_text_explanation.csv\")\n",
        "X_for_text_explanation.drop(['Unnamed: 0'], axis = 1, inplace = True)\n",
        "\n",
        "all_sents = []\n",
        "\n",
        "for each_value in correct_samples:\n",
        "  # num = X_for_text_explanation[X_for_text_explanation['id']==each_value].index.values\n",
        "  all_sents.append(X_for_text_explanation.iloc[each_value][1])\n",
        "\n",
        "all_sents"
      ],
      "metadata": {
        "id": "6zoOghziwpqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "changed_sent = all_sents[0].replace('T-shirt Topwear','')\n",
        "changed_sent"
      ],
      "metadata": {
        "id": "gGUcvBcU98vd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns = X_train.columns[0:8].tolist()\n",
        "X_text = pd.DataFrame(columns = columns)\n",
        "X_text.head()"
      ],
      "metadata": {
        "id": "1Mg0OBYV8K9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get features from changed text first\n",
        "\n",
        "tokenizer_text_features = AutoTokenizer.from_pretrained(\"Showroom/clothing_subcategory_classifier\")\n",
        "model_text_features = AutoModelForSequenceClassification.from_pretrained(\"Showroom/clothing_subcategory_classifier\")\n",
        "\n",
        "temp_dictionary = {}\n",
        "temp_list_of_dictionaries = []\n",
        "\n",
        "inputs = tokenizer_text_features(changed_sent, return_tensors=\"pt\")\n",
        "outputs = model_text_features(**inputs)\n",
        "logits = outputs.logits\n",
        "probs = logits.softmax(dim=1)\n",
        "\n",
        "topk = torch.topk(logits, 8).indices # out of index error with numbers>8 so this model calculates 8 features\n",
        "for each_value in topk[0]:\n",
        "  temp_dictionary[model_text_features.config.id2label[each_value.item()]] = probs[0][each_value.item()].item()\n",
        "\n",
        "temp_list_of_dictionaries.append(temp_dictionary)\n",
        "\n",
        "X_text = X_text.append(temp_list_of_dictionaries)\n",
        "X_text"
      ],
      "metadata": {
        "id": "bNzOtlZX2B9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# image features remain the same becasue we're not making any changes to it\n",
        "# so get the image features from \"X_all_features\" (but use only image columns)\n",
        "\n",
        "# the sample we're using is id 1615 but it's index in the table is 4\n",
        "\n",
        "X_image = X_all_features.iloc[4:5, 8:] # row number 4\n",
        "# and all columns (which are the feature) from 8 onwards, becasue the first 8 features are text\n",
        "X_image"
      ],
      "metadata": {
        "id": "U9Tl73ar4T4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_together = pd.concat([X_text, X_image], axis=0, ignore_index=True)\n",
        "X_together = pd.concat([X_text, X_image.set_index(X_text.index)], axis=1)\n",
        "\n",
        "X_together"
      ],
      "metadata": {
        "id": "cTgZTHY_51wm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# then predict on the single changed data again\n",
        "y_pred_one = model.predict(X_together)\n",
        "predictions_one = [round(value) for value in y_pred_one]\n",
        "\n",
        "# calculate accuracy\n",
        "accuracy_one = accuracy_score(y_test_one, predictions_one)\n",
        "print(\"Accuracy:\", (accuracy_one * 100.0))"
      ],
      "metadata": {
        "id": "KqKlys757CfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Counter-factual example type 3"
      ],
      "metadata": {
        "id": "8EUQroV3B9VR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# try removing something from an image"
      ],
      "metadata": {
        "id": "FllcmpARCAb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct_samples = [1758]\n",
        "correct_ids = [6]\n",
        "\n",
        "X_text = X_all_features.iloc[5:6, :8]\n",
        "X_text_new = pd.DataFrame(np.repeat(X_text.values, 4, axis=0))\n",
        "X_text_new.columns = X_text.columns\n",
        "X_text_new"
      ],
      "metadata": {
        "id": "snK7d4c0I2EG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "changed_image_list = []\n",
        "\n",
        "for i in tqdm(range(len(correct_samples))):\n",
        "\n",
        "  image_name = \"fashion-product-images-small/images/\"+str(correct_samples[i])+\".jpg\"\n",
        "  image = Image.open(image_name)\n",
        "\n",
        "  # inverting image\n",
        "  invert_image = ImageChops.invert(image)\n",
        "  changed_image_list.append(invert_image)\n",
        "  invert_image.save(\"inverted_image.png\")\n",
        "  invert_image.show()\n",
        "\n",
        "  # mirroring\n",
        "  mirror_image = ImageOps.mirror(image)\n",
        "  changed_image_list.append(mirror_image)\n",
        "  mirror_image.save(\"mirrored_image.png\")\n",
        "  mirror_image.show()\n",
        "\n",
        "  # inverting and mirroring\n",
        "  iv_image = ImageOps.mirror(invert_image)\n",
        "  changed_image_list.append(iv_image)\n",
        "  iv_image.save(\"iv_image.png\")\n",
        "  iv_image.show()\n",
        "\n",
        "  # contour\n",
        "  cont_image = image.filter(ImageFilter.CONTOUR)\n",
        "  changed_image_list.append(cont_image)\n",
        "  cont_image.save(\"cont_image.png\")\n",
        "  cont_image.show()\n"
      ],
      "metadata": {
        "id": "cf0uVioaI0mp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns = X_train.columns[8:].tolist()\n",
        "X_image = pd.DataFrame(columns = columns)\n",
        "X_image.head()"
      ],
      "metadata": {
        "id": "RmKz6YkVB9Va"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get features from changed image first\n",
        "\n",
        "extractor_image_features = AutoFeatureExtractor.from_pretrained(\"aalonso-developer/vit-base-clothing-leafs-example-full-simple_highres\")\n",
        "model_image_features = AutoModelForImageClassification.from_pretrained(\"aalonso-developer/vit-base-clothing-leafs-example-full-simple_highres\")\n",
        "\n",
        "temp_dictionary = {}\n",
        "temp_list_of_dictionaries = []\n",
        "\n",
        "for i in range(len(changed_image_list)):\n",
        "\n",
        "  temp_dictionary = {}\n",
        "  inputs = extractor_image_features(changed_image_list[i], return_tensors=\"pt\")\n",
        "\n",
        "  with torch.no_grad():\n",
        "      logits = model_image_features(**inputs).logits\n",
        "\n",
        "  probs = logits.softmax(dim=1) # we can take the softmax to get the label probabilities\n",
        "  topk = torch.topk(logits, 3).indices\n",
        "  for each_value in topk[0]:\n",
        "    temp_dictionary[model_image_features.config.id2label[each_value.item()]] = probs[0][each_value.item()].item()\n",
        "\n",
        "  temp_list_of_dictionaries.append(temp_dictionary)\n",
        "\n",
        "X_image = X_image.append(temp_list_of_dictionaries)\n",
        "X_image"
      ],
      "metadata": {
        "id": "1J6SVjcTB9Va"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_image=X_image.fillna(0)\n"
      ],
      "metadata": {
        "id": "CHFZ26FOM89p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_together = pd.concat([X_text_new, X_image], axis=1)\n",
        "X_together"
      ],
      "metadata": {
        "id": "qOBVfWsaB9Vb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# then predict on the single changed data again\n",
        "y_pred_change_images = model.predict(X_together)\n",
        "predictions_change_images = [round(value) for value in y_pred_change_images]\n",
        "\n",
        "y_test_change_images = [0,0,0,0]\n",
        "for i in range(len(y_pred_change_images)):\n",
        "  print(y_test_change_images[i], predictions_change_images[i])\n",
        "\n",
        "# calculate accuracy\n",
        "accuracy_one = accuracy_score(y_test_change_images, predictions_change_images)\n",
        "print(\"Accuracy:\", (accuracy_one * 100.0))"
      ],
      "metadata": {
        "id": "-MjouoopB9Vb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Counter-factual example type 4"
      ],
      "metadata": {
        "id": "iRwxxINGSRZ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# modify both image and text and train model"
      ],
      "metadata": {
        "id": "EOa4LgqDdQ1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct_text = 'Lotto  White Collared Jacket Topwear Fall Sports'\n",
        "correct_text = correct_text.replace('Jacket Topwear', '')\n",
        "correct_text = correct_text.replace('Sports', '')\n",
        "correct_text"
      ],
      "metadata": {
        "id": "7N3f6tlvST4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns = X_train.columns[0:8].tolist()\n",
        "X_text = pd.DataFrame(columns = columns)\n",
        "X_text.head()"
      ],
      "metadata": {
        "id": "ad2teBJfTMGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get features from changed text first\n",
        "\n",
        "tokenizer_text_features = AutoTokenizer.from_pretrained(\"Showroom/clothing_subcategory_classifier\")\n",
        "model_text_features = AutoModelForSequenceClassification.from_pretrained(\"Showroom/clothing_subcategory_classifier\")\n",
        "\n",
        "temp_dictionary = {}\n",
        "temp_list_of_dictionaries = []\n",
        "\n",
        "inputs = tokenizer_text_features(correct_text, return_tensors=\"pt\")\n",
        "outputs = model_text_features(**inputs)\n",
        "logits = outputs.logits\n",
        "probs = logits.softmax(dim=1)\n",
        "\n",
        "topk = torch.topk(logits, 8).indices # out of index error with numbers>8 so this model calculates 8 features\n",
        "for each_value in topk[0]:\n",
        "  temp_dictionary[model_text_features.config.id2label[each_value.item()]] = probs[0][each_value.item()].item()\n",
        "\n",
        "temp_list_of_dictionaries.append(temp_dictionary)\n",
        "\n",
        "X_text = X_text.append(temp_list_of_dictionaries)\n",
        "X_text"
      ],
      "metadata": {
        "id": "veCJ_nioTSpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_text_new = pd.DataFrame(np.repeat(X_text.values, 4, axis=0))\n",
        "X_text_new.columns = X_text.columns\n",
        "X_text_new"
      ],
      "metadata": {
        "id": "Q6XpWjQVThKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_together = pd.concat([X_text_new, X_image], axis=1)\n",
        "X_together"
      ],
      "metadata": {
        "id": "laAGsjj7TzYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# then predict on the single changed data again\n",
        "y_pred_change_images = model.predict(X_together)\n",
        "predictions_change_images = [round(value) for value in y_pred_change_images]\n",
        "\n",
        "y_test_change_images = [0,0,0,0]\n",
        "for i in range(len(y_pred_change_images)):\n",
        "  print(y_test_change_images[i], predictions_change_images[i])\n",
        "\n",
        "# calculate accuracy\n",
        "accuracy_one = accuracy_score(y_test_change_images, predictions_change_images)\n",
        "print(\"Accuracy:\", (accuracy_one * 100.0))"
      ],
      "metadata": {
        "id": "gv2bB4v9T3hk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Counter-factual example type 5"
      ],
      "metadata": {
        "id": "v2msXZRzVBYO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# remove the top features from the X_all_features and then train model again"
      ],
      "metadata": {
        "id": "AXfcxzENunlu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_all_features_remove = X_all_features.drop(top_feature_names, axis = 1)\n",
        "X_all_features_remove"
      ],
      "metadata": {
        "id": "5kC-LoGwVK13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting dataset\n",
        "# Training - 70%\n",
        "# Test - 30%\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_all_features_remove, y, test_size=0.3, random_state=42, stratify=y)\n"
      ],
      "metadata": {
        "id": "DiJ_FIDRtEEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define and train model\n",
        "model_remove = XGBClassifier()\n",
        "model_remove.fit(X_train, y_train)\n",
        "\n",
        "# then predict on test data\n",
        "y_pred_remove = model_remove.predict(X_test)\n",
        "predictions_remove = [round(value) for value in y_pred_remove]\n",
        "\n",
        "# calculate accuracy\n",
        "accuracy = accuracy_score(y_test, predictions_remove)\n",
        "print(\"Accuracy:\", (accuracy * 100.0))\n",
        "\n",
        "# no significant decrease in accuracy"
      ],
      "metadata": {
        "id": "cNKJBy42tYBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download all result files"
      ],
      "metadata": {
        "id": "pM2GVWHydy32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "files.download(\"confusionmatrix.png\")\n",
        "files.download(\"feature_imp_sorted.png\")\n",
        "files.download(\"featureimp_xgboost.png\")\n",
        "files.download(\"decision_tree.png\")"
      ],
      "metadata": {
        "id": "ku0k59MQd06h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}